{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85aa7c29",
   "metadata": {},
   "source": [
    "# Debugging Individual Agents in AI Project Analizer\n",
    "\n",
    "This notebook lets you run and debug each BeeAI agent in isolation. Each section will:\n",
    "1. Import the necessary agent class.\n",
    "2. Prepare a minimal environment (e.g., a test ZIP or test files).\n",
    "3. Call the agent's `handle()` method with simulated events.\n",
    "4. Capture and display outputs (logs, memory writes, emitted events).\n",
    "\n",
    "Make sure you have extracted the project into the folder:\n",
    "```\n",
    "/mnt/c/blog/ai-project-analizer\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff76a5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_DIR: /mnt/c/blog/ai-project-analizer/backup/agent_debug_tests\n"
     ]
    }
   ],
   "source": [
    "# Setup paths and logging\n",
    "import sys, os, shutil, zipfile, tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project src and root to sys.path\n",
    "sys.path.append(r\"/mnt/c/blog/ai-project-analizer/src\")\n",
    "sys.path.append(r\"/mnt/c/blog/ai-project-analizer\")\n",
    "\n",
    "# Ensure logs are printed\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG, format=\"%(asctime)s %(levelname)s %(message)s\")\n",
    "\n",
    "# Create a temporary directory for tests\n",
    "TEST_DIR = Path(\"/mnt/c/blog/ai-project-analizer/backup/agent_debug_tests\")\n",
    "if TEST_DIR.exists():\n",
    "    shutil.rmtree(TEST_DIR)\n",
    "TEST_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"TEST_DIR:\", TEST_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e0b92d",
   "metadata": {},
   "source": [
    "## Create a Sample ZIP for Testing\n",
    "\n",
    "We'll generate a small ZIP file containing a single `foo.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac0b77f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created zip at: /mnt/c/blog/ai-project-analizer/backup/agent_debug_tests/test.zip\n"
     ]
    }
   ],
   "source": [
    "# Create a simple zip file with one text file\n",
    "sample_zip_path = TEST_DIR / \"test.zip\"\n",
    "with zipfile.ZipFile(sample_zip_path, \"w\") as zf:\n",
    "    # Create a text file inside a temp location\n",
    "    tmp_file = TEST_DIR / \"foo.txt\"\n",
    "    tmp_file.write_text(\"Hello, world!\")\n",
    "    zf.write(tmp_file, arcname=\"foo.txt\")\n",
    "print(\"Created zip at:\", sample_zip_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51e1b04",
   "metadata": {},
   "source": [
    "## Debug `ZipValidatorAgent`\n",
    "\n",
    "Instantiate `ZipValidatorAgent`, monkey-patch its `emit` to capture events, and run with our test ZIP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c423345",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'beeai_framework.agent'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01magents\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mzip_validator_agent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ZipValidatorAgent\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Prepare the agent\u001b[39;00m\n\u001b[32m      4\u001b[39m zip_agent = ZipValidatorAgent()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/blog/ai-project-analizer/src/agents/zip_validator_agent.py:26\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Updated imports to use beeai_framework instead of beeai\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbeeai_framework\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01magent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Agent\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbeeai_framework\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Event\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m settings\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'beeai_framework.agent'"
     ]
    }
   ],
   "source": [
    "from src.agents.zip_validator_agent import ZipValidatorAgent\n",
    "\n",
    "# Prepare the agent\n",
    "zip_agent = ZipValidatorAgent()\n",
    "emitted = []\n",
    "# Monkey-patch emit to capture events\n",
    "zip_agent.emit = lambda event_name, payload: emitted.append((event_name, payload))\n",
    "\n",
    "# Test with valid ZIP\n",
    "event = {\"type\": \"NewUpload\", \"zip_path\": str(sample_zip_path)}\n",
    "zip_agent.handle(event)\n",
    "print(\"Emitted events for valid ZIP:\", emitted)\n",
    "\n",
    "# Test with an invalid path\n",
    "emitted.clear()\n",
    "event_bad = {\"type\": \"NewUpload\", \"zip_path\": str(TEST_DIR / \"nonexistent.zip\")}\n",
    "zip_agent.handle(event_bad)\n",
    "print(\"Emitted events for bad ZIP:\", emitted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7945f42f",
   "metadata": {},
   "source": [
    "## Debug `ExtractionAgent`\n",
    "\n",
    "Use the valid ZIP event and capture `FileDiscovered` and `ExtractionDone`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b00020f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agents.extraction_agent import ExtractionAgent\n",
    "\n",
    "# Prepare the agent\n",
    "ext_agent = ExtractionAgent()\n",
    "emitted_ext = []\n",
    "ext_agent.emit = lambda event_name, payload: emitted_ext.append((event_name, payload))\n",
    "\n",
    "# Run extraction on the valid ZIP event\n",
    "event_zip_valid = {\"type\": \"ZipValid\", \"zip_path\": str(sample_zip_path)}\n",
    "ext_agent.handle(event_zip_valid)\n",
    "print(\"Extraction emitted events:\")\n",
    "for evt in emitted_ext:\n",
    "    print(evt)\n",
    "\n",
    "# Check extracted directory\n",
    "if emitted_ext and emitted_ext[-1][0] == \"ExtractionDone\":\n",
    "    base_dir = Path(emitted_ext[-1][1][\"base_dir\"])\n",
    "    print(\"Contents of extracted directory:\", list(base_dir.rglob(\"*\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e7c58a",
   "metadata": {},
   "source": [
    "## Debug `TreeBuilderAgent`\n",
    "\n",
    "Simulate `FileDiscovered` events, then `ExtractionDone` with the previously extracted folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7d9c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agents.tree_builder_agent import TreeBuilderAgent\n",
    "\n",
    "# Find the base_dir from previous extraction\n",
    "if emitted_ext and emitted_ext[-1][0] == \"ExtractionDone\":\n",
    "    base_dir = Path(emitted_ext[-1][1][\"base_dir\"])\n",
    "else:\n",
    "    raise RuntimeError(\"Extraction did not complete successfully.\")\n",
    "\n",
    "# Prepare tree builder\n",
    "tree_agent = TreeBuilderAgent()\n",
    "# Send FileDiscovered events (for each file in base_dir)\n",
    "for file_path in base_dir.rglob(\"*\"):\n",
    "    if file_path.is_file():\n",
    "        file_event = {\"type\": \"FileDiscovered\", \"path\": str(file_path)}\n",
    "        tree_agent.handle(file_event)\n",
    "\n",
    "# Now fire ExtractionDone\n",
    "done_event = {\"type\": \"ExtractionDone\", \"base_dir\": str(base_dir)}\n",
    "tree_agent.handle(done_event)\n",
    "\n",
    "# The tree text is stored in memory\n",
    "print(\"Generated project_tree.txt:\")\n",
    "print(tree_agent.memory.get(\"project_tree.txt\", \"<none>\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0ca56e",
   "metadata": {},
   "source": [
    "## Debug `FileTriageAgent`\n",
    "\n",
    "Queue discovered files, flush on `ExtractionDone`, and capture `FileForAnalysis` and `TriageComplete`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2680100",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agents.file_triage_agent import FileTriageAgent\n",
    "\n",
    "# Prepare file triage agent\n",
    "triage_agent = FileTriageAgent()\n",
    "emitted_triage = []\n",
    "triage_agent.emit = lambda event_name, payload: emitted_triage.append((event_name, payload))\n",
    "\n",
    "# Send FileDiscovered events for all files under base_dir\n",
    "for file_path in base_dir.rglob(\"*\"):\n",
    "    if file_path.is_file():\n",
    "        file_event = {\"type\": \"FileDiscovered\", \"path\": str(file_path)}\n",
    "        triage_agent.handle(file_event)\n",
    "\n",
    "# Now send ExtractionDone\n",
    "done_event = {\"type\": \"ExtractionDone\", \"base_dir\": str(base_dir)}\n",
    "triage_agent.handle(done_event)\n",
    "\n",
    "print(\"Triage emitted events:\")\n",
    "for evt in emitted_triage:\n",
    "    print(evt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34f2852",
   "metadata": {},
   "source": [
    "## Debug `FileAnalysisAgent`\n",
    "\n",
    "Analyze each file from `FileForAnalysis` events and finalize on `TriageComplete`. Display `file_summaries.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2d2574",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agents.file_analysis_agent import FileAnalysisAgent\n",
    "import json\n",
    "\n",
    "# Prepare file analysis agent\n",
    "analysis_agent = FileAnalysisAgent()\n",
    "emitted_analysis = []\n",
    "analysis_agent.emit = lambda event_name, payload: emitted_analysis.append((event_name, payload))\n",
    "\n",
    "# Simulate FileForAnalysis events from triage\n",
    "file_for_analysis_events = [evt for evt in emitted_triage if evt[0] == \"FileForAnalysis\"]\n",
    "for _, payload in file_for_analysis_events:\n",
    "    evt = {\"type\": \"FileForAnalysis\", \"path\": payload[\"path\"], \"score\": payload.get(\"score\", 0)}\n",
    "    analysis_agent.handle(evt)\n",
    "\n",
    "# Now fire TriageComplete\n",
    "tc_event = {\"type\": \"TriageComplete\"}\n",
    "analysis_agent.handle(tc_event)\n",
    "\n",
    "print(\"FileAnalysis emitted events:\")\n",
    "for evt in emitted_analysis:\n",
    "    print(evt)\n",
    "\n",
    "# Check memory for file_summaries.json\n",
    "print(\"Memory file_summaries.json:\")\n",
    "print(analysis_agent.memory.get(\"file_summaries.json\", \"<none>\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafbd284",
   "metadata": {},
   "source": [
    "## Debug `SummarySynthesizerAgent`\n",
    "\n",
    "Feed `TreeBuilt` and `FileAnalysed` / `AnalysisComplete` events, then inspect `project_summary.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8bfaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agents.summary_synthesizer_agent import SummarySynthesizerAgent\n",
    "\n",
    "# Prepare summary synthesizer agent\n",
    "summary_agent = SummarySynthesizerAgent()\n",
    "emitted_summary = []\n",
    "summary_agent.emit = lambda event_name, payload: emitted_summary.append((event_name, payload))\n",
    "\n",
    "# Manually populate memory for tree text and file summaries\n",
    "summary_agent.memory[\"project_tree.txt\"] = tree_agent.memory.get(\"project_tree.txt\", \"\")\n",
    "# Use the list of analyses from emitted_analysis if any; else simulate one\n",
    "analyses = [payload for (name, payload) in emitted_analysis if name == \"FileAnalysed\"]\n",
    "for analysis in analyses:\n",
    "    evt = {\"type\": \"FileAnalysed\", **analysis}\n",
    "    summary_agent.handle(evt)\n",
    "\n",
    "# Now signal AnalysisComplete\n",
    "ac_event = {\"type\": \"AnalysisComplete\"}\n",
    "summary_agent.handle(ac_event)\n",
    "\n",
    "# Also signal TreeBuilt (to ensure it has the tree)\n",
    "tb_event = {\"type\": \"TreeBuilt\", \"tree_path\": \"project_tree.txt\"}\n",
    "summary_agent.handle(tb_event)\n",
    "\n",
    "print(\"SummarySynthesizer emitted events:\")\n",
    "for evt in emitted_summary:\n",
    "    print(evt)\n",
    "\n",
    "# Check memory for project_summary.txt\n",
    "print(\"\\nGenerated project_summary.txt:\")\n",
    "print(summary_agent.memory.get(\"project_summary.txt\", \"<none>\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
